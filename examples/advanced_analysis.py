#!/usr/bin/env python3
"""
–ü—Ä–∏–º–µ—Ä –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å AI Summariser
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional

from ai_summariser import TelegramSummariser

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class AdvancedAnalyzer:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Å—Ç–æ–≤"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.summariser: Optional[TelegramSummariser] = None
    
    async def __aenter__(self):
        self.summariser = await TelegramSummariser(self.db_path).__aenter__()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.summariser:
            await self.summariser.__aexit__(exc_type, exc_val, exc_tb)
        self.summariser = None
    
    async def analyze_all_folders(self) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –ø–∞–ø–æ–∫"""
        assert self.summariser is not None
        folders = await self.summariser.get_folders()
        analysis = {
            "total_folders": len(folders),
            "folders": [],
            "summary": {
                "total_posts": 0,
                "date_range": "",
                "main_topics": [],
                "sentiment": "neutral"
            }
        }
        
        all_posts = 0
        all_topics = []
        dates = []
        
        for folder in folders:
            folder_analysis = await self.analyze_folder(folder.id)
            analysis["folders"].append(folder_analysis)
            
            all_posts += folder_analysis["total_posts"]
            all_topics.extend(folder_analysis["main_topics"])
            if folder_analysis["date_range"]:
                dates.append(folder_analysis["date_range"])
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        analysis["summary"]["total_posts"] = all_posts
        analysis["summary"]["main_topics"] = list(set(all_topics))[:10]  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–µ–º—ã
        
        if dates:
            analysis["summary"]["date_range"] = f"{min(dates)} - {max(dates)}"
        
        return analysis
    
    async def analyze_folder(self, folder_id: int) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø–∞–ø–∫–∏"""
        assert self.summariser is not None
        folder_info = await self.summariser.get_folder_info(folder_id)
        if not folder_info:
            return {"error": f"–ü–∞–ø–∫–∞ {folder_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"}
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–≤–æ–¥–∫—É
        summary = await self.summariser.summarise_folder(
            folder_id=folder_id,
            limit=50,
            days_back=30
        )
        
        if not summary:
            return {
                "folder_id": folder_id,
                "folder_name": folder_info.name,
                "error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Å–≤–æ–¥–∫—É"
            }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–º—ã
        topic_analysis = await self.analyze_topics(summary.main_topics)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        activity_analysis = await self.analyze_activity(summary)
        
        return {
            "folder_id": folder_id,
            "folder_name": folder_info.name,
            "total_posts": summary.total_posts,
            "date_range": summary.date_range,
            "main_topics": summary.main_topics,
            "overall_summary": summary.overall_summary,
            "topic_analysis": topic_analysis,
            "activity_analysis": activity_analysis,
            "recent_posts": [
                {
                    "date": post.date.isoformat(),
                    "channel": post.channel_title,
                    "summary": post.summary,
                    "link": post.link
                }
                for post in summary.posts[:10]
            ]
        }
    
    async def analyze_topics(self, topics: List[str]) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —Ç–µ–º"""
        if not topics:
            return {"error": "–ù–µ—Ç —Ç–µ–º –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"}
        
        # –ó–∞–¥–∞–µ–º –≤–æ–ø—Ä–æ—Å—ã –ò–ò –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–º
        questions = [
            "–ö–∞–∫–∏–µ –∏–∑ —ç—Ç–∏—Ö —Ç–µ–º –Ω–∞–∏–±–æ–ª–µ–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã?",
            "–ö–∞–∫–∏–µ —Ç–µ–º—ã –≤—ã–∑—ã–≤–∞—é—Ç –Ω–∞–∏–±–æ–ª—å—à–∏–π –∏–Ω—Ç–µ—Ä–µ—Å?",
            "–ï—Å—Ç—å –ª–∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Ç–µ–º—ã –≤ —Å–ø–∏—Å–∫–µ?"
        ]
        
        topic_analysis = {
            "total_topics": len(topics),
            "topic_categories": [],
            "ai_insights": {}
        }
        
        # –ü—Ä–æ—Å—Ç–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–º
        categories = {
            "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": ["–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ", "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ"],
            "–Ω–æ–≤–æ—Å—Ç–∏": ["–Ω–æ–≤–æ—Å—Ç–∏", "—Å–æ–±—ã—Ç–∏—è", "–∞–Ω–æ–Ω—Å—ã"],
            "–ø—Ä–æ–±–ª–µ–º—ã": ["–ø—Ä–æ–±–ª–µ–º—ã", "–æ—à–∏–±–∫–∏", "—Å–±–æ–∏", "–∑–∞–¥–µ—Ä–∂–∫–∏"],
            "—Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏—è": ["–∏–≥—Ä—ã", "—Ñ–∏–ª—å–º—ã", "–º—É–∑—ã–∫–∞", "—Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏—è"]
        }
        
        for topic in topics:
            for category, keywords in categories.items():
                if any(keyword in topic.lower() for keyword in keywords):
                    topic_analysis["topic_categories"].append({
                        "topic": topic,
                        "category": category
                    })
                    break
            else:
                topic_analysis["topic_categories"].append({
                    "topic": topic,
                    "category": "–¥—Ä—É–≥–æ–µ"
                })
        
        return topic_analysis
    
    async def analyze_activity(self, summary) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
        return {
            "posts_per_day": summary.total_posts / 7 if summary.total_posts > 0 else 0,
            "activity_level": "–≤—ã—Å–æ–∫–∞—è" if summary.total_posts > 20 else "—Å—Ä–µ–¥–Ω—è—è" if summary.total_posts > 10 else "–Ω–∏–∑–∫–∞—è",
            "channels_count": len(set(post.channel_title for post in summary.posts)),
            "date_span": summary.date_range
        }
    
    async def generate_report(self, analysis: Dict, output_file: Optional[str] = None) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞"""
        report = f"""
# –û—Ç—á–µ—Ç AI Summariser
## –î–∞—Ç–∞: {datetime.now().strftime('%d.%m.%Y %H:%M')}

## –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
- üìÅ –í—Å–µ–≥–æ –ø–∞–ø–æ–∫: {analysis['total_folders']}
- üìä –í—Å–µ–≥–æ –ø–æ—Å—Ç–æ–≤: {analysis['summary']['total_posts']}
- üìÖ –ü–µ—Ä–∏–æ–¥: {analysis['summary']['date_range']}

## –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã
{chr(10).join(f"- {topic}" for topic in analysis['summary']['main_topics'])}

## –ê–Ω–∞–ª–∏–∑ –ø–æ –ø–∞–ø–∫–∞–º
"""
        
        for folder in analysis["folders"]:
            if "error" in folder:
                folder_name = folder.get('folder_name', f"–ü–∞–ø–∫–∞ {folder.get('folder_id', 'N/A')}")
                report += f"\n### {folder_name}\n"
                report += f"‚ùå {folder['error']}\n"
                continue
            
            report += f"""
### {folder['folder_name']}
- üìà –ü–æ—Å—Ç–æ–≤: {folder['total_posts']}
- üìÖ –ü–µ—Ä–∏–æ–¥: {folder['date_range']}
- üéØ –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã: {', '.join(folder['main_topics'][:5])}
- üìä –£—Ä–æ–≤–µ–Ω—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: {folder['activity_analysis']['activity_level']}

**–°–≤–æ–¥–∫–∞:**
{folder['overall_summary']}

**–ü–æ—Å–ª–µ–¥–Ω–∏–µ –ø–æ—Å—Ç—ã:**
"""
            
            for i, post in enumerate(folder['recent_posts'][:3], 1):
                report += f"{i}. [{post['date'][:10]}] {post['channel']}\n"
                report += f"   {post['summary'][:100]}...\n"
                if post['link']:
                    report += f"   üîó {post['link']}\n"
                report += "\n"
        
        if output_file is not None:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report)
            logger.info(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_file}")
        
        return report


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ AI Summariser - –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑")
    print("=" * 50)
    
    db_path = "/path/to/your/tg_parser.db"
    
    if not Path(db_path).exists():
        logger.error(f"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {db_path}")
        return
    
    async with AdvancedAnalyzer(db_path) as analyzer:
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –ø–∞–ø–∫–∏
            print("üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –ø–∞–ø–∫–∏...")
            analysis = await analyzer.analyze_all_folders()
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
            print("üìù –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç...")
            report = await analyzer.generate_report(
                analysis, 
                output_file="analysis_report.md"
            )
            
            # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            print(f"\nüìà –ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
            print(f"   –ü–∞–ø–æ–∫: {analysis['total_folders']}")
            print(f"   –ü–æ—Å—Ç–æ–≤: {analysis['summary']['total_posts']}")
            print(f"   –¢–µ–º: {len(analysis['summary']['main_topics'])}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            with open("analysis_data.json", "w", encoding="utf-8") as f:
                json.dump(analysis, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
            print(f"   üìÑ –û—Ç—á–µ—Ç: analysis_report.md")
            print(f"   üìä –î–∞–Ω–Ω—ã–µ: analysis_data.json")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}")


if __name__ == "__main__":
    asyncio.run(main()) 